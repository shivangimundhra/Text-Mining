{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b44666f",
   "metadata": {},
   "source": [
    "# Question -\n",
    "\n",
    "HappyDB is a corpus of 100,000+ crowd-sourced happy moments. Use this corpus to answer this question: when asked to reflect on happy moments, who are most often mentioned - spouse, parents, children, friends, or someone else?\n",
    "HappyDB is available on GitHub [1]. The cleaned data set is located at [2]. HappyDB also provides a “people dictionary” [3], which is a lexicon of common social relationships. If you can find, or create, a better lexicon of social relationships, please feel free to use it, and explain why it is a better lexicon for this task.\n",
    "Write a Python script in Jupyter Notebook and submit the .ipynb file that includes your code and your explanations in comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196ee56",
   "metadata": {},
   "source": [
    "# Step 1 \n",
    "read the csv files for cleaned_hm and people_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7f1dd219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# import countVectorizer because we will use it to find frequency of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import re\n",
    "# from nltk.tokenize import TreebankWordTokenizer\n",
    "# from nltk.tokenize import WordPunctTokenizer\n",
    "# from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "098806d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cleaned_hm csv file\n",
    "cleanedHm = pd.read_csv(\"/Users/shivangi/Downloads/cleaned_hm.csv\")\n",
    "\n",
    "# read people-dict csv file without header because this file does not have a header\n",
    "peopleDict = pd.read_csv(\"/Users/shivangi/Downloads/people-dict.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1dc9e177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>ground_truth_category</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>2</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>1936</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>206</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>6227</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid   wid reflection_period  \\\n",
       "0  27673  2053               24h   \n",
       "1  27674     2               24h   \n",
       "2  27675  1936               24h   \n",
       "3  27676   206               24h   \n",
       "4  27677  6227               24h   \n",
       "\n",
       "                                         original_hm  \\\n",
       "0  I went on a successful date with someone I fel...   \n",
       "1  I was happy when my son got 90% marks in his e...   \n",
       "2       I went to the gym this morning and did yoga.   \n",
       "3  We had a serious talk with some friends of our...   \n",
       "4  I went with grandchildren to butterfly display...   \n",
       "\n",
       "                                          cleaned_hm  modified  num_sentence  \\\n",
       "0  I went on a successful date with someone I fel...      True             1   \n",
       "1  I was happy when my son got 90% marks in his e...      True             1   \n",
       "2       I went to the gym this morning and did yoga.      True             1   \n",
       "3  We had a serious talk with some friends of our...      True             2   \n",
       "4  I went with grandchildren to butterfly display...      True             1   \n",
       "\n",
       "  ground_truth_category predicted_category  \n",
       "0                   NaN          affection  \n",
       "1                   NaN          affection  \n",
       "2                   NaN           exercise  \n",
       "3               bonding            bonding  \n",
       "4                   NaN          affection  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the dataframe\n",
    "cleanedHm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57841546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auntie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aunties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aunts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aunty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0     aunt\n",
       "1   auntie\n",
       "2  aunties\n",
       "3    aunts\n",
       "4    aunty"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at peopleDict\n",
    "peopleDict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef504d7",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Vectorize. We'll use count vectorization since we want to know how many times a word appears in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3ab428ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivangi/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# define countvectorizer\n",
    "cv = CountVectorizer(encoding = 'latin-1')\n",
    "# use countVectorizer to create fit_transform()\n",
    "vecs = cv.fit_transform(cleanedHm['cleaned_hm'])\n",
    "# get word list\n",
    "word_list = cv.get_feature_names();\n",
    "# get count list\n",
    "count_list = vecs.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d7e808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "5642\n"
     ]
    }
   ],
   "source": [
    "freq = dict(zip(word_list,count_list))\n",
    "print(freq.get('couples')) # word frequency\n",
    "print(cv.vocabulary_.get('couples')) # word index, not frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4fb10",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "add the frequency of words to the people dict dataframe for all relevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37e6925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column to a more meaningful value\n",
    "peopleDict.rename(columns = {0:'relation'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80a52f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of word frequencies of all words in peopleDict so we can later add this list to the peopleDict df\n",
    "wordFrequency = []\n",
    "for word in peopleDict['relation']:\n",
    "    wordFrequency.append(freq.get(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14a4cc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the type of list that got created\n",
    "type(wordFrequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "716a2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add word frequency as a column to the peopleDict dataframe\n",
    "peopleDict['wordFrequency'] = wordFrequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18c554c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>wordFrequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aunt</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auntie</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aunties</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aunts</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aunty</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relation  wordFrequency\n",
       "0     aunt          222.0\n",
       "1   auntie            2.0\n",
       "2  aunties            NaN\n",
       "3    aunts           26.0\n",
       "4    aunty           26.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the peopleDict dataframe\n",
    "peopleDict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c89f04a",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "get the most used relation in peopleDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ddce46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   relation  wordFrequency\n",
      "59   friend         6166.0\n"
     ]
    }
   ],
   "source": [
    "print(peopleDict[peopleDict.wordFrequency == peopleDict.wordFrequency.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571a4d85",
   "metadata": {},
   "source": [
    "Therefore, the word \"friend\" is the most used relation in these happy moments. The word is used precisely 6166 times in the entire dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
